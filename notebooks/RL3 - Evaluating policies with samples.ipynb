{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class 3: Evaluating policies with samples**\n",
    "\n",
    "1. [Everything you need to know](#everything)\n",
    "2. [Reminder](#reminder)\n",
    "3. [Evaluating policies as a stochastic approximation problem](#evaluating)\n",
    "4. [Monte Carlo sampling](#monte)\n",
    "5. [Temporal difference learning](#temporal)\n",
    "6. [Delayed updates and experience replay for TD(0)](#batch)\n",
    "    1. [Delayed updates](#delayed)\n",
    "    2. [Experience replay](#experience)\n",
    "7. [The importance of the behavior distribution](#behavior)\n",
    "8. [TD($\\lambda$)](#tdlambda)\n",
    "9. [Summary](#summary)\n",
    "10. [A few notes on value function approximation](#approx)\n",
    "    1. [Linear value function approximation](#linear)\n",
    "    2. [The tabular case is just a specific case of linear approximation](#tab)\n",
    "    3. [TD($\\lambda$) as a linear approximation update](#param)\n",
    "    4. [Non-parametric models](#nonparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous classes introduced MDPs and the Bellman equations (evaluation and optimality). These equations involve the MDP's model (transition and reward functions). We saw how to solve these equations using the model. In this class, we will investigate how one can aim to solve the evaluation equation with samples rather than with the model.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Prerequisites:**\n",
    "- Stochastic Approximation / Stochastic Gradient Descent\n",
    "- Definition of a Markov Decision Process, a policy, a value function, a stationary distribution\n",
    "- Evaluation equation\n",
    "    \n",
    "**Useful but not compulsory:**\n",
    "- Bias/variance tradeoff\n",
    "- Basic linear algebra\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"everything\"></a>Everything you need to know\n",
    "\n",
    "\n",
    "Everything you should remember after this session.\n",
    "<div class=\"alert alert-success\">\n",
    "<ul>\n",
    "<li> Learning $V^\\pi$ is a stochastic approximation problem with samples $g^\\pi_t$ of $G^\\pi_t = \\sum\\limits_{t = 0}^\\infty \\gamma^t R^\\pi_t$.<br>\n",
    "    Updates: $V(s_t) \\leftarrow V(s_t) + \\alpha \\left[ g^\\pi_t - V(s_t) \\right]$ <br>\n",
    "    Extension to batch SGD updates for $V_\\theta$: $\\theta \\leftarrow \\theta + \\alpha \\sum_{i=1}^N \\left[ g^\\pi(s_i) - V_\\theta(s_i)\\right] \\nabla_\\theta V_\\theta(s_i)$.\n",
    "<li> Monte Carlo sampling of $G^\\pi_t$: $g^\\pi_t = \\sum_{i>t} \\gamma^{i-t} r^\\pi_i$.<br>\n",
    "    Yields the online MC algorithm. Requires finite trajectories.\n",
    "<li> Temporal Difference TD(0) learning: $g^\\pi_t = r_t + \\gamma V(s_{t+1})$.<br>\n",
    "    Temporal difference $\\delta = r + \\gamma V(s') - V(s)$ or $\\delta = r + \\gamma Q(s',\\pi(s')) - Q(s,a)$<br>\n",
    "    Sample-based update. No need for finite trajectories.<br>\n",
    "    When applied to $Q$ functions, does not require to simulate $\\pi$: off-policy updates.\n",
    "<li> Unifying MC and TD: TD($\\lambda$).\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "Of course, all this seems very obscure right now and the block above will only serve as a reminder when you re-open the notebook later. We will introduce every concept intuitively and progessively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"reminder\"></a>Reminder\n",
    "\n",
    "**Value function:**  \n",
    "$V^\\pi(s)=\\mathbb{E}\\left[ \\sum\\limits_{t = 0}^\\infty \\gamma^t R_t \\quad \\Bigg| \\quad \\begin{array}{l}s_0 = s,\\\\ a_t=\\pi(s_t),\\\\ s_{t+1}\\sim p(s'|s_t,a_t),\\\\R_t = r(S_t,A_t,S_{t+1})\\end{array} \\right]$\n",
    "\n",
    "**Evaluation equation(s):**  \n",
    "$V^\\pi$ is a solution to the linear system $V = T^\\pi V$ with:\n",
    "$$\\left(T^\\pi V\\right) \\left(s\\right) = r\\left(s,\\pi(s)\\right) + \\gamma \\mathbb{E}_{s' \\sim p\\left(s'|s,\\pi(s)\\right)} V\\left(s'\\right)$$  \n",
    "\n",
    "$Q^\\pi$ is a solution to the linear system $Q = T^\\pi Q$ with:\n",
    "$$\\left(T^\\pi Q\\right) \\left(s,a\\right) = r\\left(s,a\\right) + \\gamma \\mathbb{E}_{s' \\sim p\\left(s'|s,a\\right)} Q\\left(s', \\pi\\left(s'\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"evaluating\"></a>Evaluating policies as a stochastic approximation problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write $G^\\pi(s)$ the random variable of the overall return along a trajectory controled by $\\pi$ and starting in $s$. With the previous notations:\n",
    "$$G^\\pi(s) = \\sum\\limits_{t = 0}^\\infty \\gamma^t R_t \\quad \\Bigg| \\quad \\begin{array}{l}s_0 = s,\\\\ a_t=\\pi(s_t),\\\\ s_{t+1}\\sim p(s'|s_t,a_t),\\\\R_t = r(S_t,A_t,S_{t+1}).\\end{array}$$\n",
    "\n",
    "Evaluating $V^\\pi(s)$ is estimating the mathematical expectation of $G^\\pi(s)$.\n",
    "\n",
    "Stochastic approximation theory tells us that, given a series $g^\\pi_t$ of independent realizations of $G^\\pi(s)$, the sequence\n",
    "$v_{t+1} = v_t + \\alpha_t \\left(g^\\pi_t - v_t\\right)$\n",
    "converges to $\\mathbb{E}\\left(G^\\pi(s)\\right)$, if the sequence of $\\alpha_t$ respects the Robbins-Monro conditions ($\\sum_t \\alpha_t = \\infty$ and $\\sum_t \\alpha_t^2 < \\infty$).\n",
    "\n",
    "<a href=\"#morePpi\" data-toggle=\"collapse\">Intuitive explanation of Stochastic Approximation.</a><br>\n",
    "<div id=\"morePpi\" class=\"collapse\">\n",
    "    \n",
    "For those unfamiliar with stochastic approximation procedures, we can understand the previous update as: $g^\\pi_t$ are samples estimates of $\\mathbb{E}\\left(G^\\pi(s)\\right)$. If I already have an estimation of $v_t$ of $\\mathbb{E}\\left(G^\\pi(s)\\right)$ and I receive a new sample $g^\\pi_t$, I should \"pull\" my previous estimate towards $g^\\pi_t$. But $g^\\pi_t$ carries a part of noise, so I should be cautious and only take a small step $\\alpha$ in the direction of $g^\\pi_t$.\n",
    "    \n",
    "In turn, the convergence conditions simply say that any value $V^\\pi(s)$ should be reachable given any initial guess $V(s)$, no matter how far from $V^\\pi(s)$ is from this first guess; hence the $\\sum\\limits_{t=0}^\\infty \\alpha_t = \\infty$. However, we still need the step-size to be decreasing so that we don't start oscillating around $V^\\pi(s)$ when we get closer; so to insure convergence we impose $\\sum\\limits_{t=0}^\\infty \\alpha_t^2 < \\infty$.\n",
    "</div>\n",
    "\n",
    "So this provides us with a way to estimate $V^\\pi(s)$ from experience samples rather than from a model.  \n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Policy evaluation as stochastic approximation**  \n",
    "If we can obtain independent realizations $g^\\pi(s)$ of $G^\\pi(s)$ in all $s$, we can perform stochastic approximation updates of $V$ under the form:\n",
    "$$V(s) \\leftarrow V(s) + \\alpha \\left(g^\\pi(s) - V(s)\\right).$$\n",
    "Then $V$ converges to $V^\\pi$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more modern formulation of Stochastic Approximation is Stochastic Gradient Descent. So we will slightly generalize the formulation above.  \n",
    "\n",
    "$V^\\pi$ is the function that minimizes\n",
    "$$L(V) = \\int_S \\left[ V(s) - \\mathbb{E}\\left(G^\\pi(s)\\right)\\right]^2 ds.$$\n",
    "\n",
    "Recall that in the most general case, $V$ is a function, but for the sake of clarity, we will momentarily suppose that $S$ is finite and thus $V$ is equivalent to the vector of all $V(s)$ values.\n",
    "\n",
    "Then, minimizing $L(V)$ can be done via gradient descent:\n",
    "$$\\nabla_V L(V) = \\int_S 2 \\left[ V(s) - \\mathbb{E}\\left(G^\\pi(s)\\right)\\right] \\nabla_V V(s) ds.$$\n",
    "\n",
    "Suppose we have a set of independently drawn states $\\left\\{s_i\\right\\}_{i\\in [1,N]}$. Then, this gradient can be approached via a Monte Carlo estimator:\n",
    "$$\\sum_{i=1}^N \\left[ V(s_i) - \\mathbb{E}\\left(G^\\pi(s_i)\\right)\\right] \\nabla_V V(s_i).$$\n",
    "\n",
    "In our example where $V$ is the vector of values taken in each state, \n",
    "$\\nabla_V V(s_i) = \\left[ \\begin{array}{c} 0\\\\ \\vdots\\\\ 0\\\\ 1 \\\\ 0\\\\ \\vdots\\\\ 0 \\end{array} \\right]$ \n",
    "where the \"1\" is at the position corresponding to $s_i$ in the vector $V$.\n",
    "\n",
    "As for Stochastic Approximation, if we can obtain independent realizations $g^\\pi(s_i)$ of $G^\\pi(s_i)$, then we can estimate this gradient as:\n",
    "$$d = \\sum_{i=1}^N \\left[ V(s_i) - g^\\pi(s_i)\\right] \\nabla_V V(s_i).$$\n",
    "\n",
    "And thus we have the Stochastic Gradient Descent update:\n",
    "$$V \\leftarrow V - \\alpha \\sum_{i=1}^N \\left[ V(s_i) - g^\\pi(s_i)\\right] \\nabla_V V(s_i)$$\n",
    "\n",
    "This update mechanism yields a sequence $V_t$ of value functions that converges to $V^\\pi$ if the gradient steps $\\alpha$ respect Robbins-Monro conditions.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Policy evaluation as Stochastic Gradient Descent**  \n",
    "If we can obtain independent realizations $g^\\pi(s)$ of $G^\\pi(s)$ in all $s$, we can perform Stochastic Gradient Descent updates on $V$:\n",
    "$$V \\leftarrow V + \\alpha \\sum_{i=1}^N \\left[ g^\\pi(s_i) - V(s_i)\\right] \\nabla_V V(s_i).$$\n",
    "Then $V$ converges to $V^\\pi$.\n",
    "</div>\n",
    "\n",
    "Note that if $N=1$, the update above falls back to the Stochastic Approximation update: having a sample in $s_i$ only updates $V(s_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b>Exercise</b><br>\n",
    "Redo the derivation above when $V$ is a parametric function $V_\\theta$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\"><a href=\"#SGD\" data-toggle=\"collapse\"><b>Answer:</b></a><br>\n",
    "<div id=\"SGD\" class=\"collapse\">\n",
    "\n",
    "The loss function becomes $L(\\theta) = \\int_S \\left[ V_\\theta(s) - \\mathbb{E}\\left(G^\\pi(s)\\right)\\right]^2 ds$.\n",
    "    \n",
    "The gradient estimator becomes:\n",
    "$$d = \\sum_{i=1}^N \\left[ V_\\theta(s_i) - g^\\pi(s_i)\\right] \\nabla_\\theta V_\\theta(s_i).$$\n",
    "\n",
    "And so the update becomes:\n",
    "$$\\theta \\leftarrow \\theta + \\alpha \\sum_{i=1}^N \\left[ g^\\pi(s_i) - V_\\theta(s_i)\\right] \\nabla_\\theta V_\\theta(s_i)$$\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b>Exercise</b><br>\n",
    "Redo the derivation above for a finite-dimensional function $Q$, then a parametric function $Q_\\theta$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><a href=\"#SGD-Q\" data-toggle=\"collapse\"><b>Answer:</b></a><br>\n",
    "<div id=\"SGD-Q\" class=\"collapse\">\n",
    "\n",
    "When working with $Q(s,a)$ functions we need to define $G^\\pi(s,a)$. Since\n",
    "$Q^\\pi(s,a)=\\mathbb{E}\\left[ \\sum\\limits_{t = 0}^\\infty \\gamma^t R_t \\quad \\Bigg| \\quad \\begin{array}{l}s_0 = s, a_0=a\\\\ a_t=\\pi(s_t)\\textrm{ for }t>0,\\\\ s_{t+1}\\sim p(s'|s_t,a_t),\\\\R_t = r(S_t,A_t,S_{t+1})\\end{array} \\right],$\n",
    "we have \n",
    "$$G^\\pi(s,a) = \\sum\\limits_{t = 0}^\\infty \\gamma^t R_t \\quad \\Bigg| \\quad \\begin{array}{l}s_0 = s, a_0=a\\\\ a_t=\\pi(s_t)\\textrm{ for }t>0,\\\\ s_{t+1}\\sim p(s'|s_t,a_t),\\\\R_t = r(S_t,A_t,S_{t+1}).\\end{array}.$$\n",
    "    \n",
    "For a generic, finite-dimensional function $Q$, the loss function is \n",
    "$$L(Q) = \\int_S \\int_A \\left[ Q(s,a) - \\mathbb{E}\\left(G^\\pi(s,a)\\right)\\right]^2 ds da.$$\n",
    "    \n",
    "The gradient estimator becomes:\n",
    "$$d = \\sum_{i=1}^N \\left[ Q(s_i,a_i) - g^\\pi(s_i,a_i)\\right] \\nabla_Q Q(s_i,a_i).$$\n",
    "\n",
    "And so the update becomes:\n",
    "$$Q \\leftarrow Q + \\alpha \\sum_{i=1}^N \\left[ g^\\pi(s_i,a_i) - Q(s_i,a_i)\\right] \\nabla_Q Q(s_i).$$\n",
    "    \n",
    "For a parametric function $Q_\\theta$, the loss function becomes \n",
    "$$L(\\theta) = \\int_S \\int_A \\left[ Q_\\theta(s,a) - \\mathbb{E}\\left(G^\\pi(s,a)\\right)\\right]^2 ds da.$$\n",
    "\n",
    "The gradient estimator becomes:\n",
    "$$d = \\sum_{i=1}^N \\left[ Q_\\theta(s_i,a_i) - g^\\pi(s_i,a_i)\\right] \\nabla_\\theta Q_\\theta(s_i,a_i).$$\n",
    "\n",
    "And so the update becomes:\n",
    "$$\\theta \\leftarrow \\theta + \\alpha \\sum_{i=1}^N \\left[ g^\\pi(s_i,a_i) - Q_\\theta(s_i,a_i)\\right] \\nabla_\\theta Q_\\theta(s_i).$$\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, overall, if we manage to draw independent samples $g^\\pi(s_i)$ of $G^\\pi(s)$ in all $s\\in S$, we can **learn** the value $V^\\pi$ (or $Q^\\pi$) of policy $\\pi$.  \n",
    "We will now introduce a few methods that differ only in how they calculate the $g^\\pi(s_i)$ samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"monte\"></a>Monte Carlo sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to estimate $V^\\pi(s)$ but we don't have access to the MDP's model. Instead, we can interact with it and draw experience samples.\n",
    "\n",
    "Then, an immediate way to estimate $V^\\pi(s)$ is to take the empirical average of a series if realizations of the $\\sum\\limits_{t = 0}^\\infty \\gamma^t R_t$ random variable.\n",
    "\n",
    "In plain words: simulate $\\pi$ from $s$ a certain number of times to obtain trajectories, observe and accumulate the rewards along each trajectory, take the empirical average over all trajectories.\n",
    "\n",
    "That is precisely what we did in the first class to estimate the value of the starting state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300012b5c1a542939831f8da5c7f62af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "value estimate: 0.013286309084390775\n",
      "value variance: 0.0761077431172768\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/RL1_exercice1.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "import gym\n",
    "import gym.envs.toy_text.frozen_lake as fl\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "nb_episodes = 100000\n",
    "horizon = 200\n",
    "gamma = 0.9\n",
    "Vepisode = np.zeros(nb_episodes)\n",
    "for i in trange(nb_episodes):\n",
    "    env.reset()\n",
    "    for t in range(horizon):\n",
    "        next_state, r, done,_ = env.step(fl.RIGHT)\n",
    "        Vepisode[i] += gamma**t * r\n",
    "        if done:\n",
    "            break\n",
    "print(\"value estimate:\", np.mean(Vepisode))\n",
    "print(\"value variance:\", np.std(Vepisode))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can we generalize this to learning the value $V^\\pi$ in all states?\n",
    "\n",
    "Let us start with a fully **offline Monte-Carlo** algorithm. The idea is simple: start from $s$, run the policy until termination (or for a long number of steps), repeat for a number of episodes, then update the value of all encountered states. This requires to store in memory full episodes (it also requires that the episodes be finite-length).\n",
    "\n",
    "But we can immediately do better with an **online Monte-Carlo** method. It is almost the same idea: start from $s$, run the policy until termination (or for a long number of steps) then update the value of all encountered states before restarting an episode.  \n",
    "\n",
    "Let $(s_0, r_0, s_1, \\ldots, s_T)$ be the sequence of transitions of such an episode.  \n",
    "For the sake of clarity we will slim down our notations: $g^\\pi(s_t)$ becomes $g_t$.  \n",
    "Then, this sequence provides a sample $g_t$ of $G^\\pi(s_t)$ for all $s_t$ visited during the simulations. \n",
    "<div class=\"alert alert-success\"><b>Monte Carlo return:</b>\n",
    "$$g_t = \\sum_{i>t} \\gamma^{i-t} r_i$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Consider the policy that always moves right in FrozenLake and implement an online Monte-Carlo estimatior for $g_t$, that you will use in a Stochastic Approximation method to obtain $V^\\pi$.  \n",
    "We decide we can tolerate a 0.001 error on $V^\\pi$ so, to keep things simple, we set a constant $\\alpha=0.001$.  \n",
    "Take $\\gamma = 0.9$. Run 100000 episodes of maximum 1000 time steps each.  \n",
    "After each episode, compare the value function obtained with that computed with the model-based approaches of the previous class (use the cell below to recall `V_pi0` from the previous class).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/RL2_exercise5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55241e34f0b4dbd8743833904aebeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.01460524 0.0116672  0.02965184 0.         0.01978357 0.\n",
      " 0.06083133 0.         0.05169227 0.15472781 0.18644593 0.\n",
      " 0.         0.28891098 0.57793886 0.        ]\n",
      "[0.01307768 0.01175958 0.02743902 0.         0.01875499 0.\n",
      " 0.06402439 0.         0.04943897 0.14604158 0.18597561 0.\n",
      " 0.         0.30082967 0.55589431 0.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/RL3_exercise1.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "import gym\n",
    "import gym.envs.toy_text.frozen_lake as fl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "# parameters\n",
    "gamma = 0.9\n",
    "alpha = 0.001\n",
    "max_steps = 1000\n",
    "max_episodes = 100000\n",
    "V = np.zeros((env.observation_space.n))\n",
    "\n",
    "# error plotting\n",
    "error = np.zeros((max_episodes)) # used to track the convergence to V_pi0...\n",
    "cumulated_steps = np.zeros((max_episodes)) # ... against the number of samples\n",
    "\n",
    "for ep in trange(max_episodes):\n",
    "    x = env.reset()\n",
    "    episode = []\n",
    "    # Run episode\n",
    "    for t in range(max_steps):\n",
    "        y,r,d,_ = env.step(fl.RIGHT)\n",
    "        episode.append([x,r])\n",
    "        if d==True:\n",
    "            cumulated_steps[ep] = cumulated_steps[ep-1] + t\n",
    "            break\n",
    "        else:\n",
    "            x=y\n",
    "    # Update values\n",
    "    T = len(episode)\n",
    "    G = np.zeros((T))\n",
    "    G[-1] = episode[-1][1] # derniere recompense\n",
    "    x = episode[-1][0]\n",
    "    V[x] = V[x] + alpha * (G[-1] - V[x])\n",
    "    for t in range(-2,-T-1,-1):\n",
    "        G[t] = episode[t][1] + gamma*G[t+1]\n",
    "        x = episode[t][0]\n",
    "        V[x] = V[x] + alpha * (G[t] - V[x])\n",
    "    error[ep] = np.max(np.abs(V-V_pi0))\n",
    "\n",
    "print(V)\n",
    "print(V_pi0)\n",
    "plt.plot(cumulated_steps,error)\n",
    "plt.figure()\n",
    "plt.semilogy(cumulated_steps,error);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So online Monte-Carlo allows us to update $V^\\pi$ episode after episode. Some values are better estimated than others depending on how often the corresponding state was visited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo estimation has some flaws nonetheless. It still requires to store one full episode in memory before $V$ is updated. Also, one rare value for $r_t$ affects directly all the value of the states encountered before $s_t$. So we can question the robustness of this estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"temporal\"></a>Temporal difference learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to replace Monte-Carlo (MC) estimation by a step by step update that only takes $(s_t,r_t,s_{t+1})$ as an input. The key remark we make is that once the $(s_t,r_t,s_{t+1})$ transition is over we can update our knowledge of $V(s_t)$ by using $r_t+\\gamma V(s_{t+1})$. This estimate uses $V(s_{t+1})$ to *bootstrap*[1] the estimator of $V(s_t)$.\n",
    "\n",
    "[1] This *bootstrap* operation has nothing to do with the statistical procedure of *bootstrapping*.\n",
    "\n",
    "To get an intuitive understanding of why we can do that, take the following example. You are driving from home to the airport. Half-way, you realize traffic is denser than you usually estimate and you're already 5 minutes behind schedule. Home is $s_t$, half-way is $s_{t+1}$, the elapsed time between $s_{t}$ and $s_{t+1}$ is $r_t$. To update your belief $V(s_t)$ about the average length of the trip home$\\rightarrow$airport, you don't need to wait until you reach the airport (as a Monte-Carlo estimate would have required). Instead, you can update this belief using $r_t+V(s_{t+1})$, the sum of what you just observed and what you currently estimate for the rest of the trip. As long as you update all states often enough, the whole procedure should converge to the true $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idea, which was first introduced in R. Sutton's **[Learning to predict by the methods of temporal differences](https://link.springer.com/article/10.1007/BF00115009)** article, has a strong parallel with the evaluation equation. This equation was:\n",
    "$$V^\\pi \\left(s\\right) = r\\left(s,\\pi(s)\\right) + \\gamma \\mathbb{E}_{s' \\sim p\\left(s'|s,\\pi(s)\\right)} V^\\pi \\left(s'\\right)$$  \n",
    "\n",
    "What we expressed intuitively in the previous paragraph is that the sample $g_t$ of $V^\\pi(s_t)$ can be built by summing $r_t$ and $\\gamma V_t(s_{t+1})$:\n",
    "$$g_t = r_t + \\gamma V_t(s_{t+1}).$$\n",
    "\n",
    "Note that in the expression above, we have used $V_t$ to emphasize that we use the function $V$ as it was at time step $t$ to define the target $g^\\pi_t$ used in the update that will provide $V_{t+1}$.\n",
    "\n",
    "Formally, this comes directly from the evaluation operator. Let's rewrite $T^\\pi$ in terms of random variables.\n",
    "$$(T^\\pi V)(s) = \\mathbb{E}_{R,S'}\\left[ R + \\gamma V(S') \\right]$$\n",
    "\n",
    "Since $V^\\pi$ is the fixed point of $T^\\pi$, by taking $g_t = r_t + \\gamma V_t(s_{t+1})$ we are taking one stochastic approximation step in the direction of $T^\\pi V_t$. \n",
    "\n",
    "**Bootstrapping** (in this particular context) is the operation of using the value of $V_t(s_{t+1})$ in the update of $V$.\n",
    "\n",
    "Then the stochastic approximation update becomes what is called the **TD(0) update**:\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**TD(0) update:**  \n",
    "$$V(s_t) \\leftarrow V(s_t) + \\alpha \\left(r_t + \\gamma V(s_{t+1}) - V(s_t)\\right).$$\n",
    "    \n",
    "This update consists in taking one stochastic approximation step in the direction of $T^\\pi V$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generalization to the batch stochastic gradient descent update is:\n",
    "$$V \\leftarrow V + \\alpha \\sum_{i=1}^N \\left[ r_i + \\gamma V(s_{i+1}) - V(s_i)\\right] \\nabla_V V(s_i).$$\n",
    "\n",
    "And in particular, for a parametric function $V_\\theta$:\n",
    "$$\\theta \\leftarrow \\theta + \\alpha \\sum_{i=1}^N \\left[ r_i + \\gamma V(s_{i+1}) - V(s_i) \\right] \\nabla_\\theta V_\\theta(s_i)$$\n",
    "\n",
    "Let's stress this out one last time:  \n",
    "TD(0) does not directly solve $V=\\mathbb{E}\\left[\\sum_t\\gamma^t R_t \\right]$, contrarily to MC. Instead, it implements stochastic approximation on top of the repeated application of the $T^\\pi$ operator. So it solves $V_{n+1} = T^\\pi V_n$. At each step $t$, it takes the current value function $V_t$, draws one or several samples from $T^\\pi V_t$ and approximates $T^\\pi V_t$ by taking one step of gradient descent from $V_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\delta_t=r_t + \\gamma V_t(s_{t+1}) - V_t(s_t)$ is called the prediction **temporal difference** (hence the name TD(0) for the algorithm - the \"0\" will be explained in the section on TD($\\lambda$)). It is the difference between our estimate $V_t(s_t)$ *before* obtaining the information of $r_t$, and the bootstrapped value $r_t+\\gamma V_t(s_{t+1})$.\n",
    "<div class=\"alert alert-success\"><b>Temporal difference:</b>\n",
    "$$\\delta=r + \\gamma V(s') - V(s)$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TD(0) update is a sample-by-sample update (no need to remember full episodes) and, more importantly, it is adapted to non-episodic environments (with no terminal states).\n",
    "\n",
    "Often, TD methods converge faster and are more robust estimators than Monte Carlo ones (but not always)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Consider the policy that always moves right in FrozenLake and implement a TD(0) estimation for $V^\\pi$.  \n",
    "Again, we decide we can tolerate a 0.001 error on $V^\\pi$ so, to keep things simple, we set $\\alpha=0.001$.  \n",
    "Take $\\gamma = 0.9$ and run the algorithm for 2000000 time steps.<br>\n",
    "After each episode, compare the value function obtained with that computed with the model-based approaches of the previous class.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5d74410b834f9892b2742324687a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.01241707 0.01162678 0.02622748 0.         0.01754208 0.\n",
      " 0.06231301 0.         0.04779655 0.14152244 0.18349582 0.\n",
      " 0.         0.2998404  0.55989421 0.        ]\n",
      "[0.01307768 0.01175958 0.02743902 0.         0.01875499 0.\n",
      " 0.06402439 0.         0.04943897 0.14604158 0.18597561 0.\n",
      " 0.         0.30082967 0.55589431 0.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/RL3_exercise2.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "import gym\n",
    "import gym.envs.toy_text.frozen_lake as fl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "# parameters\n",
    "gamma = 0.9\n",
    "alpha = 0.001\n",
    "max_steps = 2000000\n",
    "V = np.zeros((env.observation_space.n))\n",
    "\n",
    "# error plotting\n",
    "error = np.zeros((max_steps)) # used to track the convergence to V_pi0\n",
    "\n",
    "x = env.reset()\n",
    "for t in trange(max_steps):\n",
    "    y,r,d,_ = env.step(fl.RIGHT)\n",
    "    V[x] = V[x] + alpha * (r+gamma*V[y]-V[x])\n",
    "    error[t] = np.max(np.abs(V-V_pi0))\n",
    "    if d==True:\n",
    "        x = env.reset()\n",
    "    else:\n",
    "        x=y\n",
    "\n",
    "print(V)\n",
    "print(V_pi0)\n",
    "plt.plot(error)\n",
    "plt.figure()\n",
    "plt.semilogy(error);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b>Exercise:</b><br>\n",
    "In the previous exercise, every experience sample $(s,r,s')$ was obtained by simulating $\\pi$. Why is it necessary to simulate $\\pi$? What would happen if we simulated another policy?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><a href=\"#TD-V\" data-toggle=\"collapse\"><b>Answers:</b></a><br>\n",
    "<div id=\"TD-V\" class=\"collapse\">\n",
    "\n",
    "We need to simulate $\\pi$ because of the definition of $g^\\pi_t$: it is a realization of the overall return *under policy $\\pi$*.\n",
    "    \n",
    "In Monte Carlo estimation, if we run another policy $\\pi'$, then we obtain samples for $g^{\\pi'}_t$ which are not informative for the estimation of $V^\\pi$.\n",
    "    \n",
    "In TD learning, even if $V(s')$ is a good estimator of $V^\\pi(s')$, we need $s'$ to be sampled according to $p(s'|s,\\pi(s))$ to obtain unbiased samples $r + \\gamma V(s')$.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Can you design a TD(0) algorithm on state-action values functions $Q(s,a)$ that estimates $Q^\\pi$ for a given policy $\\pi$?  \n",
    "Does this algorithm require that the transitions from $s$ to $s'$ be sampled using $\\pi$?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><a href=\"#TD-Q\" data-toggle=\"collapse\"><b>Answers:</b></a><br>\n",
    "<div id=\"TD-Q\" class=\"collapse\">\n",
    "We wish to estimate $Q(s,a)$:\n",
    "$$Q^\\pi(s,a) = \\mathbb{E}\\left( \\sum\\limits_{t=0}^\\infty \\gamma^t r\\left(s_t, a_t\\right) \\bigg| s_0 = s, a_0=a, \\pi \\right) = r(s,a) + \\gamma \\sum\\limits_{s'\\in S}p(s'|s,a) Q^\\pi(s',\\pi(s'))$$\n",
    "\n",
    "So we can write our temporal difference by bootstrapping with $Q(s',\\pi(s'))$. Suppose the last sample was $(s,a,r,s')$.\n",
    "$$\\delta = r + \\gamma Q(s',\\pi(s')) - Q(s,a)$$\n",
    "And the update of $Q$ goes as:\n",
    "$$Q(s,a) \\leftarrow Q(s,a) + \\alpha \\delta$$\n",
    "As long as all state-action pairs $(s,a)$ are sampled infinitely often as $t\\rightarrow\\infty$, and under the Robbins-Monro conditions, this procedure should converge to $Q^\\pi$. So the transitions should be sampled for every state-action pair and thus do not require to apply $\\pi(s)$ in $s$.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><b>TD(0) temporal difference update on $Q$-functions:</b><br>\n",
    "For a sample $(s,a,r,s')$, the temporal difference is:\n",
    "$$\\delta = r + \\gamma Q(s',\\pi(s')) - Q(s,a)$$\n",
    "And the TD update is:\n",
    "$$Q(s,a) \\leftarrow Q(s,a) + \\alpha \\left[ r + \\gamma Q(s',\\pi(s')) - Q(s,a) \\right]$$\n",
    "As long as all state-action pairs $(s,a)$ are sampled infinitely often as $t\\rightarrow\\infty$, and under the Robbins-Monro conditions, this procedure converges to $Q^\\pi$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, in the exercise above, the samples $(s,a,r,s')$ do not require $a=\\pi(s)$. Even better, they actually require to try all possible actions in $s$ for the procedure to converge (not only $\\pi(s)$). So this TD(0) algorithm on $Q$-functions is an **off-policy** algorithm. One can obtain the value $Q^\\pi$ of a policy $\\pi$ without applying $\\pi$ for sample collection. This will prove very useful during the class on model-free control.\n",
    "\n",
    "We will call $\\beta$ the *behavior policy*. It is the policy being applied to interact with the environment. Off-policy evaluation algorithms can use a behavior policy that is different than the policy being evaluated. We will call *behavior distribution* the distributions $\\rho^\\beta(s)$ over states and $\\rho^\\beta(s,a)$ over state-action pairs, induced by applying $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b>Exercise:</b><br>\n",
    "Let's implement TD(0) on $Q$-functions.<br>\n",
    "To insure that all states and actions are sampled infinitely often, take a behavior policy that acts randomly in each state.<br>\n",
    "Take $\\gamma=0.9$ and run the algorithm for 2000000 time steps.<br>\n",
    "In order to speed up convergence, we can initialize $Q(s,a)$ to the value found previously for $V^\\pi(s)$.<br>\n",
    "Use the cell below (inspired from the class on model-based policy evaluation) to retrieve the true value of $Q^\\pi$ and display convergence of TD(0).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym.envs.toy_text.frozen_lake as fl\n",
    "import numpy as np\n",
    "\n",
    "# Model based evaluation\n",
    "def policy_Qeval_iter(pi, epsilon, max_iter):\n",
    "    Q1 = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    Q2 = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    residuals = np.zeros((max_iter))\n",
    "    for i in range(max_iter):\n",
    "        for x in range(env.observation_space.n):\n",
    "            for a in range(env.action_space.n):\n",
    "                Q2[x][a] = 0\n",
    "                outcomes = env.unwrapped.P[x][a]\n",
    "                for o in outcomes:\n",
    "                    p = o[0]\n",
    "                    y = o[1]\n",
    "                    r = o[2]\n",
    "                    Q2[x][a] += p * (r + gamma*Q1[y][pi[y]])\n",
    "        residuals[i] = np.max(np.abs(Q2-Q1))\n",
    "        Q1[:] = Q2\n",
    "        if residuals[i]<epsilon:\n",
    "            residuals = residuals[:i+1]\n",
    "            break\n",
    "    return Q1, residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e222647a0c3141dcadfdc3b5ebbf5d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qtrue:\n",
      " [[0.01336154 0.01299541 0.01299541 0.01128441]\n",
      " [0.0074009  0.01210468 0.01173854 0.01562206]\n",
      " [0.0309353  0.02271414 0.02741792 0.01173854]\n",
      " [0.00822116 0.00822116 0.         0.00822116]\n",
      " [0.02428337 0.02039986 0.01868886 0.00947803]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.06400324 0.05578208 0.06400324 0.00822116]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.02039986 0.05859612 0.04938528 0.06419063]\n",
      " [0.10502161 0.16080369 0.14599835 0.07058743]\n",
      " [0.22974521 0.21054845 0.18595444 0.06298753]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.13400704 0.25697394 0.30076472 0.21054845]\n",
      " [0.31275603 0.59030728 0.5558731  0.47933168]\n",
      " [0.         0.         0.         0.        ]]\n",
      "number of iterations: 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d62f0bf4114df985b216c21bc1b218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Max error: 0.019736193946709057\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/RL3_exercise3.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "import gym\n",
    "import gym.envs.toy_text.frozen_lake as fl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "# Policy definition and parameters\n",
    "pi0 = fl.RIGHT*np.ones((env.observation_space.n),dtype=np.int)\n",
    "gamma = 0.9\n",
    "alpha = 0.001\n",
    "\n",
    "Qtrue, residuals = policy_Qeval_iter(pi0,1e-4,10000)\n",
    "print(\"Qtrue:\\n\", Qtrue)\n",
    "print(\"number of iterations:\", residuals.size)\n",
    "plt.plot(residuals)\n",
    "plt.figure()\n",
    "plt.semilogy(residuals)\n",
    "\n",
    "# TD(0) evaluation of Qpi\n",
    "# parameters\n",
    "gamma = 0.9\n",
    "alpha = 0.001\n",
    "max_steps=2000000\n",
    "Q = np.transpose(np.tile(V, (4,1)))\n",
    "\n",
    "error = np.zeros((max_steps))\n",
    "x = env.reset()\n",
    "for t in trange(max_steps):\n",
    "    a = np.random.randint(4)\n",
    "    y,r,d,_ = env.step(a)\n",
    "    Q[x][a] = Q[x][a] + alpha * (r+gamma*Q[y][fl.RIGHT]-Q[x][a])\n",
    "    error[t] = np.max(np.abs(Q-Qtrue))\n",
    "    if d==True:\n",
    "        x = env.reset()\n",
    "    else:\n",
    "        x=y\n",
    "\n",
    "print(\"Max error:\", np.max(np.abs(Q-Qtrue)))\n",
    "plt.figure()\n",
    "plt.plot(error)\n",
    "plt.figure()\n",
    "plt.semilogy(error);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a way to *learn* $Q^\\pi$ for a given policy $\\pi$. This provides us with a way to run Policy Iteration without a model and thus build an agent that learns an optimal policy from samples. This will be covered in the next class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"batch\"></a>Delayed updates and experience replay for TD(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of clarity and re-usability we will work directly with $Q$ functions in what follows but the same argument holds for $V$ functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"delayed\"></a>Delayed updates\n",
    "\n",
    "We have seen that TD(0), at each time step, takes a gradient step in the direction of $T^\\pi Q$.\n",
    "\n",
    "The result of this gradient step is an approximation of $T^\\pi Q$.\n",
    "\n",
    "The previous class on model-based policy optimization indicated that despite an approximation operator $\\mathcal{A}$ with controlled error, the sequence $V_{n+1} = \\mathcal{A} T^\\pi V_n$ still converged to a neighborhood of $V^\\pi$. The same result holds for the sequence $Q_{n+1} = \\mathcal{A} T^\\pi Q_n$.\n",
    "\n",
    "One single step of stochastic gradient descent makes for a poor approximator. Given a fixed function $Q_n$, if we repeat a certain number $C$ of such gradient steps, we can hope to obtain a better estimate of $T^\\pi Q_n$. So there is an interest in keeping two $Q$ functions. The first is the current estimator, which plays the role of $Q_n$, upon which we apply $T^\\pi$, and which we call the *target* function $Q^-$. The second is the one we actually optimize upon and which aims at approximating $T^\\pi Q^-$; we write it $Q$. Every $C$ gradient steps, we replace $Q^-$ by $Q$ and repeat.\n",
    "\n",
    "Consequently, this procedure of delayed updates trades off advancing in the $Q_{n+1} = \\mathcal{A} T^\\pi Q_n$ sequence for better approximation properties for $\\mathcal{A}$.\n",
    "\n",
    "This makes more apparent the remark made before that TD(0) actually solves the $Q_{n+1} = T^\\pi Q_n$ sequence and thus successively minimizes a sequence of losses:\n",
    "$$L_n(Q) = \\| Q - T^\\pi Q_n \\|_2.$$\n",
    "The loss changes everytime we replace $Q_n$ by $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "What's the value of $C$ in vanilla TD(0)?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><a href=\"#vanillaTD0\" data-toggle=\"collapse\"><b>Answers:</b></a><br>\n",
    "<div id=\"vanillaTD0\" class=\"collapse\">\n",
    "Vanilla TD(0) replaces $Q^-$ by $Q$ at every step, so $C=1$.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"experience\"></a>Experience replay\n",
    "In order to be able to perform stochastic gradient steps using more than one sample, one needs to keep samples in memory.\n",
    "\n",
    "Recall the loss we defined to introduce the stochastic gradient update:\n",
    "$$L(Q) = \\int_S \\left[ Q(s) - \\mathbb{E}\\left(G^\\pi(s)\\right)\\right]^2 ds da.$$\n",
    "\n",
    "Recall also that $d = \\sum_{i=1}^N \\left[ Q(s_i) - g^\\pi(s_i)\\right] \\nabla_Q Q(s_i)$ is an unbiased estimate of $\\nabla_Q L(Q)$ only if the $g^\\pi(s_i)$ are drawn **independently** and **identically** according to the distribution of $G^\\pi(s)$.\n",
    "\n",
    "This last condition can only be verified if \n",
    "1. the $s_i$ are drawn independently of each other and always according to the same distribution $\\rho(s)$, and\n",
    "2. given $s_i$, the realizations $g^\\pi(s_i)$ are drawn independently of each other and according to the distribution of $G^\\pi(s_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "What do you think? Is condition 1 verified in vanilla TD(0)? What about condition 2?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><a href=\"#iid\" data-toggle=\"collapse\"><b>Answers:</b></a><br>\n",
    "<div id=\"iid\" class=\"collapse\">\n",
    "\n",
    "Let's write $(s_i,a_i,r_i,s'_i)$ the $i$th sample and $\\beta$ the behavior policy.\n",
    "    \n",
    "Condition 1 is not verified for vanilla TD(0). It is true that if the behavior policy is constant, then on average the samples $s_i$ are drawn **identically**, according this policy's stationary state distribution $\\rho^\\beta(s)$. However, successive samples are not drawn **independently** by definition, since $\\mathbb{P}(S_{t+1})$ is actually conditionned by $S_t$ and $A_t=\\beta(S_t)$.\n",
    "\n",
    "    \n",
    "Condition 2, on the other hand is easier to verify for TD(0) updates: since the reward $r_i$ and the next state $s'_i$ are only conditionned by $s_i$ and $a_i=\\beta(s_i)$, the $g^\\pi(s_i) = r_i + \\gamma Q(s'_i,\\pi(s'_i))$ are all drawn identically and independently of each other.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite this, TD(0) with tabular function representation still converges as long as states and actions are tried frequently enough. In some cases of function approximation this is also still true. But we might have found a major issue here in the most general case.\n",
    "\n",
    "One way to (approximately) recover the conditional independence of sampled states $s_i$ is to store a large number of samples $(s_i,a_i,r_i,s'_i)$ in memory, and draw samples uniformly at random from this memory for the TD(0) updates. This idea was first introduced by Lin in his 1992 **[Self-improving reactive agents based on reinforcement learning, planning and teaching](https://link.springer.com/article/10.1007/BF00992699)** article, under the name of *experience replay* (although his derivation was not exactly the same and applied to the Q-learning algorithm which we reserve for another class).\n",
    "\n",
    "The memory of samples is generally called an *experience replay memory* or *experience replay buffer*, since it allows the learning agent to store past experience in memory and recall it (replay it) as many times as necessary to facilitate learning.\n",
    "\n",
    "Drawing uniformly randomly from a replay buffer preserves the stationary distribution which generated the samples and breaks the conditional dependency between successive samples in a trajectory.\n",
    "\n",
    "Combined with the delayed updates introduced earlier, this yields a general, practical algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**TD(0) with delayed updates and experience replay:**  \n",
    "Given a set of samples $\\left\\{(s_i,a_i,r_i,s'_i)\\right\\}_{i\\in [1,N]}$ all drawn from a fixed behavior distribution, and a *target* function $Q^-$, the gradient update is:\n",
    "$$Q \\leftarrow Q + \\alpha \\sum_{i=1}^N \\left[ r_i + \\gamma Q^-(s'_{i},\\pi(s'_i)) - Q_\\theta(s_i,a_i) \\right] \\nabla_Q Q(s_i,a_i)$$\n",
    "As long as all state-action pairs $(s,a)$ are sampled infinitely often as $t\\rightarrow\\infty$, under the Robbins-Monro conditions, and under repeated substitution of $Q^-$ by $Q_\\theta$ every $C$ gradient updates, this procedure converges to $Q^\\pi$ that minimizes $\\|Q - Q^\\pi \\|_2$.\n",
    "</div>\n",
    "\n",
    "We can write the same update in the case of parametric function approximation.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**TD(0) with delayed updates, experience replay and parametric function approximation:**  \n",
    "Given a set of samples $\\left\\{(s_i,a_i,r_i,s'_i)\\right\\}_{i\\in [1,N]}$ all drawn from a fixed behavior distribution, a *target* function $Q^-$,  and a parametric function approximator $Q_\\theta$, the gradient update is:\n",
    "$$\\theta \\leftarrow \\theta + \\alpha \\sum_{i=1}^N \\left[ r_i + \\gamma Q^-(s'_{i},\\pi(s'_i)) - Q_\\theta(s_i,a_i) \\right] \\nabla_\\theta Q_\\theta(s_i,a_i)$$\n",
    "As long as all state-action pairs $(s,a)$ are sampled infinitely often as $t\\rightarrow\\infty$, under the Robbins-Monro conditions, and under repeated substitution of $Q^-$ by $Q_\\theta$ every $C$ gradient updates, this procedure converges to $\\theta^\\pi$ that minimizes $\\|Q_\\theta - Q^\\pi \\|_2$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"behavior\"></a>The importance of the behavior distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have written above that TD(0) on $Q$ functions is an off-policy algorithm since it will estimate $Q^\\pi$ whatever the behavior policy is, as long as this policy explores all state-action pairs infinitely often.\n",
    "\n",
    "This is actually only true if we are working with tabular representations of $Q$ functions.\n",
    "\n",
    "Let's return to the gradient descent formulation for a minute. We wrote that the loss was:\n",
    "$$L(Q) = \\int_S \\int_A \\left[ Q(s,a) - \\mathbb{E}\\left(G^\\pi(s,a)\\right)\\right]^2 ds da.$$\n",
    "    \n",
    "And we wrote the Monte Carlo estimate of this loss' gradient:\n",
    "$$d = \\sum_{i=1}^N \\left[ Q(s_i,a_i) - g^\\pi(s_i,a_i)\\right] \\nabla_Q Q(s_i,a_i).$$\n",
    "\n",
    "This is actually only correct if the samples $(s_i, a_i)$ are drawn uniformly in $S \\times A$. But in practice, the samples are drawn in $S\\times A$ according to the behavior distribution $\\rho^\\beta(s,a)$.\n",
    "\n",
    "Let us get back to the general formulation of stochastic gradient descent. For this, we will introduce a distribution $\\Gamma$ over $S\\times A\\times \\mathbb{R}$ that describes the joint distribution of state-action pairs $(s,a)$ and long term returns $G^\\pi(s,a)$ under policy $\\pi$. So, given a behavior distribution $\\rho^\\beta(s,a)$, essentially:\n",
    "$$\\Gamma(s,a,g^\\pi) = \\rho^\\beta(s,a) \\mathbb{P}(G^\\pi(s,a)=g^\\pi|s,a)$$\n",
    "\n",
    "Then finding $Q^\\pi$ amounts to solving the minimization problem $\\min_Q L(Q)$ with:\n",
    "\\begin{align*}\n",
    "L(Q) &= \\mathbb{E}_{s,a,g^\\pi \\sim \\Gamma} \\left[ \\left(Q(s,a) - g^\\pi\\right) \\right],\\\\\n",
    "     &= \\int_S \\int_A \\int_\\mathbb{R} \\left[ Q(s,a) - g^\\pi \\right]^2 \\Gamma(s,a,g^\\pi) ds da dg^\\pi.\n",
    "\\end{align*}\n",
    "\n",
    "Then, **if the samples $(s,a,g^\\pi)$ are drawn according to $\\Gamma(s,a,g^\\pi)$**, the Monte Carlo estimate\n",
    "$$d = \\sum_{i=1}^N \\left[ Q(s_i,a_i) - g^\\pi(s_i,a_i)\\right] \\nabla_Q Q(s_i,a_i)$$\n",
    "is actually a correct estimate of $\\nabla_Q L(Q)$.\n",
    "\n",
    "What does it mean that $(s,a,g^\\pi)$ are drawn according to $\\Gamma(s,a,g^\\pi)$? It means state-action pairs are drawn according to $\\rho^\\beta(s,a)$ and the $g^\\pi(s_i,a_i)$ follow the distribution of $G^\\pi(s,a)$\n",
    "\n",
    "Otherwise, this Monte Carlo estimate it is a biased estimator that minimizes another loss function; for example one defined by another behavior distribution $\\rho^\\beta(s,a)$.\n",
    "\n",
    "So when we are summing elements drawn from the replay memory, or when we are using single samples drawn from the interaction with the MDP, we are actually minimizing the loss function defined specifically by $\\rho^\\beta(s,a)$. And in the end, for another behavior distribution, the resulting minimizer $Q$ of the loss might be different from the one obtained by using samples collected with $\\rho^\\beta$.\n",
    "\n",
    "So, does that mean TD(0) on $Q$ functions is not really off-policy?\n",
    "\n",
    "In the case of tabular representations, the fact that the gradients $\\nabla_Q Q(s_i,a_i)$ are actually indicator functions of $(s_i, a_i)$ limits the impact of having different distributions on $S\\times A$. In this case, the minimizers of $L(Q)$ are actually all the same across behavior distributions, as long as the behavior distribution's support spans fully $S\\times A$.\n",
    "\n",
    "However, this nice property is lost in the general case, in particular in the case of function approximation $Q_\\theta$. This has motivated the introduction of the **[Gradient Temporal Difference](https://proceedings.neurips.cc/paper/2008/hash/e0c641195b27425bb056ac56f8953d24-Abstract.html)** family of algorithms. This topic is beyond the scope of this class but the interested reader is encouraged to look at **[H. R. Maei's PhD thesis](https://era.library.ualberta.ca/items/fd55edcb-ce47-4f84-84e2-be281d27b16a)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"tdlambda\"></a>TD($\\lambda$)\n",
    "\n",
    "If this is the first time you read this notebook, this part can be skipped.\n",
    "\n",
    "With Monte Carlo (MC) and TD(0), we have two methods with different features:\n",
    "- TD(0): 1-sample update with bootstrapping\n",
    "- MC: $\\infty$-sample update with no bootstrapping\n",
    "\n",
    "What's inbetween?\n",
    "- inbetween: $n$-sample update with bootstrapping\n",
    "\n",
    "We define the **$n$-step target** or **$n$-step return** $G^{(n)}_t$ from state $s_t$ as the random variable:\n",
    "\n",
    "$$\n",
    "\\begin{array}{l|l}\n",
    "G_t = R_t + \\gamma R_{t+1} + \\gamma^2 R_{t+2} + \\ldots & \\textrm{MC}\\\\\n",
    "G^{(1)}_t = R_t + \\gamma V_t(S_{t+1}) & 1\\textrm{-step TD = TD(0)}\\\\\n",
    "G^{(2)}_t = R_t + \\gamma R_{t+1} + \\gamma^2 V_t(S_{t+2}) & 2\\textrm{-step TD}\\\\\n",
    "G^{(n)}_t = R_t + \\gamma R_{t+1} + \\gamma^2 R_{t+2} + \\ldots + \\gamma^n V_t(S_{t+n}) & n\\textrm{-step TD}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "And we define the **$n$-step TD update** as:\n",
    "<div class=\"alert alert-success\"><b>$n$-step TD update:<b>\n",
    "$$V(s_t) \\leftarrow V(s_t) + \\alpha \\left[ R^{(n)}_t - V(s_t) \\right]$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercise:**  \n",
    "Suppose that the immediate reward $R$ has a constant variance $\\sigma^2$ and that for all states $s$ the estimator $V(s)$ of $V^\\pi(s)$ has bias $\\epsilon$.  \n",
    "What is the variance of $G_t^{(n)}$?  \n",
    "What is the bias of $\\mathbb{E}\\left(G_t^{(n)}(s)\\right)$ as an estimator of $V^\\pi(s)$?  \n",
    "Comment on the impact of choosing a certain value for $n$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><a href=\"#biasvariance\" data-toggle=\"collapse\"><b>Answers:</b></a><br>\n",
    "<div id=\"biasvariance\" class=\"collapse\">\n",
    "\n",
    "Reminder: $var(X+Y)=var(X)+var(Y)$ and $var(aX)=a^2 var(X)$.  \n",
    "Consequently:\n",
    "\\begin{align*}\n",
    "    var(G_t^{(n)}) &= \\sum_{i=0}^{n-1} \\gamma^{2i} \\sigma^2 + var(V_t(S_{t+n}))\\\\\n",
    "     &= \\frac{1-\\gamma^n}{1-\\gamma}\\sigma^2 + var(V_t(S_{t+n}))\n",
    "\\end{align*}\n",
    "    \n",
    "The variance grows with $n$, both because $1-\\gamma^n$ grows with $n$ and because $S_{t+n}$ has larger variance as $n$ grows.\n",
    "    \n",
    "On the bias side:\n",
    "\\begin{align*}\n",
    "    \\mathbb{E}\\left(G_t^{(n)}(s)\\right) - V^\\pi(s) &= \\mathbb{E}\\left(G_t^{(n)}(s)\\right) - \\mathbb{E}\\left(\\sum_{i=0}^\\infty \\gamma^t R_t\\right)\\\\\n",
    "    &=\\mathbb{E}\\left(\\sum_{i=0}^{n-1} \\gamma^i R_{t+i} + \\gamma^n V_t(S_{t+n})\\right)  - \\mathbb{E}\\left(\\sum_{i=0}^\\infty \\gamma^t R_t\\right)\\\\\n",
    "    &=\\gamma^n \\left[ \\mathbb{E}\\left(V_t(S_{t+n})\\right) - \\mathbb{E}\\left(\\sum_{i=n}^\\infty \\gamma^t R_t \\right) \\right]\\\\\n",
    "    &=\\gamma^n \\left[ \\mathbb{E}\\left(V_t(S_{t+n})\\right) - V_t(S_{t+n}) \\right]\\\\\n",
    "    &=\\gamma^n \\epsilon\n",
    "\\end{align*}\n",
    "    \n",
    "So the bias decreases with $n$. This makes sense since $V_t$'s importance is weighted by $\\gamma^n$.\n",
    "    \n",
    "Consequently, choosing a value for $n$ is making a bias-variance tradeoff. Small $n$ means small variance an large bias, large $n$ means large variance and small bias. Thus, choosing an intermediate value has in interest in accelerating the convergence of TD algorithms.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So MC corresponds to an $\\infty$-step TD update.  \n",
    "    \n",
    "The $n$-step TD update algorithm converges to the true $V^\\pi$ just as TD(0) or MC. It requires to wait for $n$ time steps before performing an update.\n",
    "\n",
    "Remark: for finite-length  episodes of length $T$, all $n$-step returns for $n>T-t$ are equal to the Monte Carlo return $G_t$.\n",
    "\n",
    "So $n$-step TD updates bridge a gap between MC and TD(0). But it's not quite satisfying yet because we never really know what value of $n$ is appropriate to speed up convergence for a given problem. An interesting property is that we can mix $n$ and $m$-step returns together. Consider $G^{mix}_t = \\frac{1}{3} G^{(2)}_t + \\frac{2}{3} G^{(4)}_t$.\n",
    "Then the update $V(s_t) \\leftarrow V(s_t) + \\alpha \\left[G^{mix}_t - V(s_t)\\right]$ still converges to $V^\\pi$. More generally, convex sums of $n$-step returns yield update procedures that still converge to $V^\\pi$.\n",
    "\n",
    "Now, take $\\lambda\\in [0,1]$ and consider the $\\lambda$-return $G^\\lambda_t$:\n",
    "<div class=\"alert alert-success\"><b>$\\lambda$-return:</b>\n",
    "$$G^\\lambda_t = \\left(1-\\lambda\\right) \\sum\\limits_{n=1}^\\infty \\lambda^{n-1}G_t^{(n)}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\lambda$-return is the mixing of *all* $n$-step returns, with weights $(1-\\lambda) \\lambda^{n-1}$. So, an agent performing a $\\lambda$-return update looks one step in the future and uses that step to update $V(s)$ with weight $(1-\\lambda)$, then looks 2 steps into the future and updates $V(s)$ with a weight $\\lambda (1-\\lambda)$ and so on. The illustrative figure below is an excerpt from **Reinforcement Learning: an introduction** by Sutton and Barto.\n",
    "\n",
    "<img src=\"img/TD_lambda_forward.png\"></img>\n",
    "\n",
    "To get a better understanding of the $\\lambda$-return and to set ideas, let us consider a finite length episode $(s_t, r_t, s_{t+1}, \\ldots, s_T)$. Since the episode ends after $T$, we have $\\forall k>0, \\ G^{(T-t+k)}_t = G_t$. Thus, we can split the $\\lambda$-return sum in two:\n",
    "\n",
    "\\begin{align*}\n",
    "G^\\lambda_t & = \\left(1-\\lambda\\right) \\sum\\limits_{n=1}^{T-t-1} \\lambda^{n-1}G_t^{(n)} + \\left(1-\\lambda\\right) \\sum\\limits_{n=T-t}^{\\infty} \\lambda^{n-1}G_t^{(n)}\\\\\n",
    "& = \\left(1-\\lambda\\right) \\sum\\limits_{n=1}^{T-t-1} \\lambda^{n-1}G_t^{(n)} + \\left(1-\\lambda\\right) \\lambda^{T-t-1} \\sum\\limits_{n=T-t}^{\\infty} \\lambda^{n-T+t} G_t^{(n)}\\\\\n",
    "& = \\left(1-\\lambda\\right) \\sum\\limits_{n=1}^{T-t-1} \\lambda^{n-1}G_t^{(n)} + \\left(1-\\lambda\\right) \\lambda^{T-t-1} \\sum\\limits_{k=0}^{\\infty} \\lambda^{k} G_t^{(T-t+k)}\\\\\n",
    "& = \\left(1-\\lambda\\right) \\sum\\limits_{n=1}^{T-t-1} \\lambda^{n-1}G_t^{(n)} + \\lambda^{T-t-1} G_t\\\\\n",
    "\\end{align*}\n",
    "\n",
    "So we have $G^\\lambda_t = \\left(1-\\lambda\\right) \\sum\\limits_{n=1}^{T-t-1} \\lambda^{n-1}G_t^{(n)} + \\lambda^{T-t-1} G_t$.\n",
    "- When $\\lambda = 0$, it is a $TD(0)$ update (hence the \"0\" in TD(0)).\n",
    "- When $\\lambda = 1$, it is a MC update.\n",
    "So we can define the **$\\lambda$-return algorithm** that generalizes on TD(0) and MC:\n",
    "<div class=\"alert alert-success\"><b>$\\lambda$-return algorithm:</b>\n",
    "$$V(s_t) \\leftarrow V(s_t) + \\alpha \\left[G^{\\lambda}_t - V(s_t)\\right] $$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all very nice and we have replaced the choice of $n$ by the choice of $\\lambda$, which seems less sensitive. But, still, we don't know how to compute those $n$-step returns, and the $\\lambda$-return, without running $n$-step episodes (and thus infinite episodes for the $\\lambda$-return in the general case).\n",
    "\n",
    "This is where we need to flip the little man in the drawing above to make him look backwards in time. When an agent transitions from $s$ to $s'$ and obtains reward $r$, it can compute the $1$-step return for $s$ and perform the corresponding $1$-step TD update. Then, as it transitions from $s'$ to $s''$ and observes $r'$ it can perform the $1$-step TD update in $s'$, but also the $2$-step TD update in $s$! An so on for future transitions. So, incrementally, as time unrolls, the agent will include the $n$-step updates in the $\\lambda$-return of $s$ as they become available. In the limit, when $t\\rightarrow\\infty$, the $\\lambda$-return in every state will be complete and the agent will have completed a $\\lambda$-return algorithm. This figure below (excerpt from **Reinforcement Learning: an introduction** by Sutton and Barto) illustrates this *backward-view* on TD updates.\n",
    "\n",
    "<img src=\"img/TD_lambda_backward.png\"></img>\n",
    "\n",
    "This seems to imply that we need to remember the states we went through, which is quite the same as remembering full episodes for MC updates. But since we want to update a state seen $n$ steps ago with a weight $\\lambda^n (1-\\lambda)$, we just need to remember, for each state, the last time we visited it (and we can forget about the trajectory linking states together). This way, we store $|S|$ values at all time, instead of an increasingly long sequence of transitions. In order to do this, we introduce the notion of **eligibility trace**:\n",
    "<div class=\"alert alert-success\"><b>Eligibility trace of state $s$:</b>\n",
    "$$e_t(s) = \\left\\{\\begin{array}{ll}\n",
    "\\gamma \\lambda e_{t-1}(s) & \\textrm{if }s\\neq s_t\\\\\n",
    "1 & \\textrm{if }s = s_t\n",
    "\\end{array}\\right.$$\n",
    "</div>\n",
    "\n",
    "Initially, all states have an eligibility trace of zero. The eligibility trace of an unvisited state decays exponentially. So $e_t(s)$ measures how old the last visit of $s$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that two alternative definitions of eligibility traces prevail:\n",
    "<ul>\n",
    "    <li> \"<b>replacing traces</b>\": $e_t(s) = 1\\textrm{ if }s = s_t$\n",
    "    <li> \"<b>accumulating traces</b>\": $e_t(s) = e_{t-1}(s) + 1\\textrm{ if }s = s_t$\n",
    "</ul>\n",
    "Often (not always), replacing traces are used in practice.<br>\n",
    "<br>\n",
    "And finally we can define the TD($\\lambda$) algorithm:\n",
    "<div class=\"alert alert-success\"><b>TD($\\lambda$) algorithm:</b><br>\n",
    "Given a new sample $(s_t,a_t,r_t,s_t')$.\n",
    "<ol>\n",
    "<li> Temporal difference $\\delta = r_t+\\gamma V(s_t') - V(s_t)$.\n",
    "<li> Update eligibility traces for all states<br>\n",
    "$e(s) \\leftarrow \\left\\{\\begin{array}{ll}\n",
    "\\gamma \\lambda e(s) & \\textrm{if } s\\neq s_t\\\\\n",
    "1 & \\textrm{if } s=s_t\n",
    "\\end{array}\\right.$\n",
    "<li> Update all state's values $V(s) \\leftarrow V(s) + \\alpha e(s) \\delta$\n",
    "</ol>\n",
    "Initially, $e(s)=0$.\n",
    "</div>\n",
    "\n",
    "Properties and remarks:\n",
    "- Earlier states are given $e(s)$ *credit* for the TD error $\\delta$\n",
    "- If the environment contains terminal states, then $e$ should be reset to zero whenever a new trajectory begins.\n",
    "- If $\\lambda=0$, $e(s)=0$ except in $s_t$ $\\Rightarrow$ standard TD(0)\n",
    "- For $0<\\lambda<1$, $e(s)$ indicates a distance $s \\leftrightarrow s_t$ is in the episode.\n",
    "- If $\\lambda=1$, $e(s)=\\gamma^\\tau$ where $\\tau=$ duration since last visit to $s_t$ $\\Rightarrow$ MC method<br>\n",
    "TD(1) implements Monte Carlo estimation on non-episodic problems!<br>\n",
    "TD(1) learns incrementally for the same result as MC\n",
    "- **TD($\\lambda$) is equivalent to the $\\lambda$-return algorithm.**\n",
    "- The value of $\\lambda$ can even be changed during the algorithm without impacting convergence.\n",
    "- TD($\\lambda$) is an on-policy algorithm: samples must be collected following the policy under evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that TD($\\lambda$) is already a batch update (it already updates all state values) but not in the sense of SGD batches.\n",
    "\n",
    "However, in the presentation given above, since the eligibility trace $e(s)$ is defined state by state, the formulation of TD($\\lambda$) is limited to discrete state spaces and tabular function representations. The section on function approximation further down will provide an extension of TD($\\lambda$) to linear function approximation.\n",
    "\n",
    "The extension of TD($\\lambda$) to the off-policy setting has been undertaken in the more general work about **[Gradient Temporal Differences](https://era.library.ualberta.ca/items/fd55edcb-ce47-4f84-84e2-be281d27b16a)** quoted earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b>Exercise:</b><br>\n",
    "Implement a TD($\\lambda$) algorithm to estimate $V^\\pi$ fo the policy that always goes right. As before, take a constant $\\alpha=0.001$, $\\gamma=0.9$ and $\\lambda=0.5$. Run the algorithm for 2000000 steps.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/RL3_exercise4.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"summary\"></a>Summary\n",
    "\n",
    "- Prediction = evaluation of a given behaviour\n",
    "- Learning $V^\\pi$ is a stochastic approximation problem with samples $g^\\pi_t$ of $G^\\pi_t = \\sum\\limits_{t = 0}^\\infty \\gamma^t R^\\pi_t$.\n",
    "- Monte Carlo estimation: $g^\\pi_t = \\sum_{i>t} \\gamma^{i-t} r^\\pi_i$.\n",
    "- Temporal Difference TD(0) learning: $g^\\pi_t = r_t + \\gamma V(s_{t+1})$.\n",
    "- Unifying MC and TD: TD($\\lambda$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"approx\"></a>A few notes on value function approximation\n",
    "\n",
    "If this is the first time you read this notebook, this part can be skipped (but please come back later, it's still quite important).\n",
    "\n",
    "Often, $S$ is not finite (or is just too large to be enumerated). Consequently, $\\mathcal{F}(S,\\mathbb{R})$ has infinite (or just too large) dimension. Thus, tabular representations of $V$ are not possible and one needs to turn to function representations $V_\\theta$ or $Q_\\theta$ with parameters $\\theta$. In this section, we provide a very short introduction to approximation methods for $V$ and $Q$.\n",
    "\n",
    "The FrozenLake example is a toy problem with very few states (moreover discrete). It does not lend itself to a convincing demonstration of value function approximation. We shall remain at the theoretical level for the following considerations and reserve practice for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"linear\"></a>Linear value function approximation\n",
    "\n",
    "Suppose we write $V$ as a linear model:\n",
    "$$V(s) = \\theta^T \\varphi(s) = \\sum_{i=1}^K \\theta_i \\varphi_i(s)$$\n",
    "\n",
    "We wish to approximate $V(s)$ as a linear combination of features $\\varphi(s)=\\left(\\varphi_i(s)\\right)_{i\\in[1,K]}$. This way, $V$ lives in the $K$-dimensional function space $span(\\varphi)$. We have plenty of families of functions that we can rely on and the user's expertise plays a big role in choosing a proper **functional basis**. Generally speaking, we would expect the following properties from a good basis:\n",
    "- the target $V^\\pi$ can be closely approximated by its projection on $\\varphi$\n",
    "- given an initial $V_0 \\in span(\\varphi)$ and the recurrence relation $V_{n+1} = \\Pi_\\varphi (T^\\pi V_n)$ (where $\\Pi_\\varphi$ is the projection operator on $span(\\varphi)$), $V_n$ should be a \"close enough\" approximation of $T^\\pi V_n$. This property is illustrated by the figure below with $Q$ instead of $V$ - excerpt from **[Least-Squares Policy Iteration](https://www.jmlr.org/papers/v4/lagoudakis03a.html)** by M. G. Lagoudakis and R. Parr (2003).\n",
    "- $\\varphi$ should form a basis (that is $\\varphi_i \\bot \\varphi_j$)\n",
    "\n",
    "<img src=\"img/projection.png\" style=\"width: 600px;\"></img>\n",
    "\n",
    "If $\\sum_{i=1}^K \\varphi_i(s) = 1$, then $V_\\theta$ is called an *averager*. Averagers are known to be well-behaved for iterative function approximation. Otherwise, other non-averager families of functions are commonly used:\n",
    "\n",
    "- $\\cos$, $\\sin$ over state variables (mimics the Fourier transform, extends to wavelet bases)\n",
    "- polynomials of the state variables (mimics the Taylor expansion)\n",
    "- radial basis functions of the state variables (performs local approximation, extends to kernel smoothing).\n",
    "- among averagers, piecewise constant local functions $\\varphi_i(s) \\in \\{0;1\\}$ group *neighborhoods* in the state space together (note the similarity with tree-based regressors).\n",
    "\n",
    "A very straightforward way of building feature sets is to define features depending on a single state variable and then using the tensor product in order to obtain all possible combinations of sigle-variable features. More formally and more generally, suppose $S \\subset S_1\\times \\ldots \\times S_k$ and suppose $\\varphi^{(i)}$ defines $d_i$ features over $S_k$; then the tensor product $\\varphi^{(1)} \\otimes \\ldots \\otimes \\varphi^{(k)}$ yields $d=d_1\\ldots d_k$ feature functions on $S$. But there is a catch, the number of these resulting features grows exponentially with $k$ and so does the dimension of the value function's search space $span(\\varphi)$: that is the **curse of dimensionality** that makes searching for a value function exponentially more difficult as the state space dimension grows.\n",
    "\n",
    "Additionnaly, there is **no guarantee** that, for a given $V_n \\in span(\\varphi)$, $T^\\pi V_n$ actually lives in $span(\\varphi)$.\n",
    "\n",
    "But on the bright side, given an initial state $s_0$, the actual reachable space $S'$ given $\\pi$ might be much smaller than $S$. So, in practice, we just need to obtain a good approximation of $V$ on the subspace $S'$.\n",
    "\n",
    "Anyway, to conclude this short paragraph on feature engineering:\n",
    "- good feature engineering in RL is even more crucial than in supervised learning.\n",
    "- it can be very problem-dependent.\n",
    "- good function approximators (generally non-parametric to avoid the fixed $span(\\varphi)$) are of crucial importance.\n",
    "We will discuss non-linear and non-parametric function approximation a bit further in the notebook.\n",
    "\n",
    "Linear function approximation has played a major role in the RL literature, in particular for temporal differences methods. The **[Policy Evaluation with Temporal Differences](https://www.jmlr.org/papers/v15/dann14a.html)** survey by C. Dann et al. (2014) provides a great overview of this literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"tab\"></a>The tabular case is just a specific case of linear approximation\n",
    "\n",
    "In the discrete state space case, consider the averager defined as:\n",
    "$$\\varphi_i(s) = \\left\\{\\begin{array}{ll}1 & \\textrm{if }s=s_i\\\\ 0 & \\textrm{otherwise}\\end{array}\\right.$$\n",
    "Feature function $\\varphi_i$ is the indicator function of state $s_i$. Therefore, we have $|S|$ feature functions. So when we write $V(s) = \\sum_{i=1}^{|S|} \\theta_i \\varphi_i(s)$, we actually have $V(s_i) = \\theta_i$. Therefore the tabular representation of $V$ is equivalent to a linear model with the $\\varphi_i$ feature functions.\n",
    "\n",
    "Based on the previous remark, let us rewrite TD($\\lambda$) as a linear model update (we take the accumulating traces version; the replacing traces case is equivalent). We had previously:<br>\n",
    "Given a new sample $(s_t,a_t,r_t,s_t')$.\n",
    "<ol>\n",
    "<li> Temporal difference $\\delta = r_t+\\gamma V(s_t') - V(s_t)$.\n",
    "<li> Update eligibility traces for all states<br>\n",
    "$e(s) \\leftarrow \\left\\{\\begin{array}{ll}\n",
    "\\gamma \\lambda e(s) & \\textrm{if } s\\neq s_t\\\\\n",
    "1 + \\gamma \\lambda e(s)& \\textrm{if } s=s_t\n",
    "\\end{array}\\right.$\n",
    "<li> Update all state's values $V(s) \\leftarrow V(s) + \\alpha e(s) \\delta$\n",
    "</ol>\n",
    "Initially, $e(s)=0$.\n",
    "\n",
    "The temporal difference can be rewritten $\\delta = r_t+\\gamma\\theta^T \\varphi(s_t') - \\theta^T \\varphi(s_t)$.\n",
    "\n",
    "The eligibility trace update can be rewritten $e \\leftarrow \\varphi(s) + \\gamma \\lambda e$.\n",
    "\n",
    "Similarly the value update can be rewritten $\\theta \\leftarrow \\theta + \\alpha e \\delta$.\n",
    "\n",
    "Remark:  \n",
    "Recall the discussion on the importance of the behavior distribution? We concluded that tabular representations were a specific case where TD(0) is truly off-policy because the influence of a sample was limited to the value of $Q$ in the corresponding $(s,a)$ pair. This discussion can be generalized for averagers (although it remains an approximation): such local models are well-behaved to suffer less from the shift in behavior distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"param\"></a>TD($\\lambda$) as a linear approximation update\n",
    "\n",
    "We generalize the previous result to the general linear model case:\n",
    "<div class=\"alert alert-success\"><b>TD($\\lambda$) with linear function approximation:</b><br>\n",
    "With $V(s) = \\sum_{i=1}^K \\theta_i \\varphi_i(s)$, $e \\in \\mathbb{R}^K$.<br>\n",
    "Initially, $e=0$.<br>\n",
    "Given a new sample $(s_t,a_t,r_t,s_t')$.\n",
    "<ol>\n",
    "<li> Temporal difference $\\delta = r_t+\\gamma\\theta^T \\varphi(s_t') - \\theta^T \\varphi(s_t)$.\n",
    "<li> Update eligibility traces for all states $e \\leftarrow \\varphi(s) + \\gamma \\lambda e$\n",
    "<li> Update value function $\\theta \\leftarrow \\theta + \\alpha e \\delta$\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "Note that we have provided the results above without proof. We will admit them and refer the reader to RL textbooks for a rigorous justification.\n",
    "\n",
    "Further reading on TD($\\lambda$) with linear function approximation: \n",
    "**[True Online TD($\\lambda$)](http://proceedings.mlr.press/v32/seijen14.html)** by H. Van Seijen and R. Sutton (2014).  \n",
    "An unpublished negative result that somehow follows from this article is also that in the general case it is not possible to have a TD($\\lambda$) algorithm performing on non-linear function approximation and being equivalent to the $\\lambda$-return algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"nonparam\"></a>Non-parametric models\n",
    "\n",
    "Non-parametric models generally refer to function approximators that do not rely on an a-priori fixed finite-dimensional search space and allows the representation space to evolve as needed. Among those non-parametrics models, one can count:\n",
    "- linear approximations that incrementally enrich the functional basis (e.g. **[this article](https://dl.acm.org/doi/abs/10.1145/1390156.1390251)**).\n",
    "- general supervised learning methods: SVMs, k-nearest neighbours (kernel smoothing methods), Gaussian Processes, tree-based methods, neural networks, etc.\n",
    "  In this second category, it is generally useful to distinguish between\n",
    "  - methods that explicitly minimize the L2 loss defined earlier (e.g. neural networks),\n",
    "  - methods that minimize some other loss (e.g. random forests) and provide alternate (better or worse guarantees).\n",
    "\n",
    "One quickly realizes that the frontier between parametric and non-parametric models is blur. In the general case of a $s \\mapsto V(s)$ function approximator, the general idea is to feed this approximator with samples of the form $(s, r+\\gamma V(s'))$. But beware: most of the nice results are generally lost when one leaves the realm of linear function approximation. More precisely, when one combines **function approximation**, **off-policy learning** and **bootstrapping** in a temporal difference method, all results are generally lost. This has been studied as the **[Deadly triad of Reinforcement Learning](https://arxiv.org/abs/1812.02648v1)** (H. Van Hasselt et al., 2018)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
