# Bellman equations, characterizing optimal policies

* [Home](https://supaerodatascience.github.io/reinforcement-learning/)
* [Github repository](https://github.com/SupaeroDataScience/reinforcement-learning/)

The previous class (RL1) introduced the model of Markov Decision Processes as a way to describe discrete-time, stochastic, dynamical systems. Our focus is on controling such systems. For this we want to characterize what makes a policy optimal and how to find it. This class covers the model-based resolution of MDPs, in particular via Dynamic Programming.

[Notebook](https://github.com/SupaeroDataScience/reinforcement-learning/blob/master/notebooks/RL2%20-%20Bellman%20equations%2C%20characterizing%20optimal%20policies.ipynb)

