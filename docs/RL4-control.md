# Solving the optimality equation with samples

* [Home](https://supaerodatascience.github.io/reinforcement-learning/)
* [Github repository](https://github.com/SupaeroDataScience/reinforcement-learning/)

The last class showed we can *learn* a policy's value function using only interaction samples. In this class, we focus on solving the optimality equation and estimating optimal value functions and policies from interaction samples. We will cover temporal difference based algorithms such as Q-learning and SARSA.

[Notebook](https://github.com/SupaeroDataScience/reinforcement-learning/blob/master/notebooks/RL4%20-%20Control%20problems%2C%20model-free%20Policy%20Optimization.ipynb)

