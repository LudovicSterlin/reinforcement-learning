# Evaluating policies with samples

* [Home](https://supaerodatascience.github.io/reinforcement-learning/)
* [Github repository](https://github.com/SupaeroDataScience/reinforcement-learning/)

The previous classes introduced MDPs and the Bellman equations (evaluation and optimality). These equations involve the MDP's model (transition and reward functions). We saw how to solve these equations using the model. In this class, we will investigate how one can aim to solve the evaluation equation with samples rather than with the model.

[Notebook](https://github.com/SupaeroDataScience/reinforcement-learning/blob/master/notebooks/RL3%20-%20Evaluating%20policies%20with%20samples.ipynb)

